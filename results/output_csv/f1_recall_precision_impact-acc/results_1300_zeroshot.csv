Model_Type,Metric,Infrastructural impact,Political impact,Financial impact,Ecological impact,Agricultural impact,Human health impact
meta-llama/Llama-3.1-8B-Instruct,Precision,0.7759,0.2736,0.3879,0.3111,0.5333,0.5865
meta-llama/Llama-3.1-8B-Instruct,Recall,0.8036,0.9016,0.8469,0.5185,0.7,0.6667
meta-llama/Llama-3.1-8B-Instruct,F1,0.7895,0.4198,0.5321,0.3889,0.6054,0.624
meta-llama/Llama-3.1-8B-Instruct,Accuracy,0.7943,0.5657,0.5829,0.7486,0.7914,0.7314
gpt-4,Precision,0.6804,0.3828,0.4061,0.3448,0.5556,0.5537
gpt-4,Recall,0.8869,0.8033,0.949,0.5556,0.75,0.8376
gpt-4,F1,0.77,0.5185,0.5688,0.4255,0.6383,0.6667
gpt-4,Accuracy,0.7457,0.74,0.5971,0.7686,0.8057,0.72
gpt-4o,Precision,0.713,0.5287,0.5436,0.3913,0.6216,0.6579
gpt-4o,Recall,0.9464,0.7541,0.8265,0.6667,0.8625,0.8547
gpt-4o,F1,0.8133,0.6216,0.6559,0.4932,0.7225,0.7435
gpt-4o,Accuracy,0.7914,0.84,0.7571,0.7886,0.8486,0.8029
mistralai/Mixtral-8x7B-Instruct-v0.1,Precision,0.7933,0.4024,0.4396,0.4107,0.6197,0.5461
mistralai/Mixtral-8x7B-Instruct-v0.1,Recall,0.7169,0.541,0.8247,0.4259,0.557,0.6581
mistralai/Mixtral-8x7B-Instruct-v0.1,F1,0.7532,0.4615,0.5735,0.4182,0.5867,0.5969
mistralai/Mixtral-8x7B-Instruct-v0.1,Accuracy,0.7752,0.7787,0.658,0.8161,0.8218,0.7011
gpt-3.5-turbo,Precision,0.7551,0.4157,0.4435,0.3194,0.5904,0.5591
gpt-3.5-turbo,Recall,0.881,0.6066,0.5612,0.4259,0.6125,0.6068
gpt-3.5-turbo,F1,0.8132,0.4933,0.4955,0.3651,0.6012,0.582
gpt-3.5-turbo,Accuracy,0.8057,0.7829,0.68,0.7714,0.8143,0.7086
Qwen/Qwen2.5-7B-Instruct,Precision,0.6863,0.2707,0.3699,0.2409,0.3697,0.4341
Qwen/Qwen2.5-7B-Instruct,Recall,0.8333,0.5902,0.551,0.6111,0.55,0.4786
Qwen/Qwen2.5-7B-Instruct,F1,0.7527,0.3711,0.4426,0.3455,0.4422,0.4553
Qwen/Qwen2.5-7B-Instruct,Accuracy,0.7371,0.6514,0.6114,0.6429,0.6829,0.6171
mistralai/Mistral-7B-Instruct-v0.2,Precision,0.7975,0.2377,0.2936,0.2906,0.4452,0.6212
mistralai/Mistral-7B-Instruct-v0.2,Recall,0.7738,0.8689,0.9796,0.6296,0.8125,0.7009
mistralai/Mistral-7B-Instruct-v0.2,F1,0.7855,0.3732,0.4518,0.3977,0.5752,0.6586
mistralai/Mistral-7B-Instruct-v0.2,Accuracy,0.7971,0.4914,0.3343,0.7057,0.7257,0.7571
deepseek-chat,Precision,0.7488,0.7073,0.5932,0.35,0.6667,0.6519
deepseek-chat,Recall,0.9226,0.4754,0.7143,0.3889,0.65,0.7521
deepseek-chat,F1,0.8267,0.5686,0.6481,0.3684,0.6582,0.6984
deepseek-chat,Accuracy,0.8143,0.8743,0.7829,0.7943,0.8457,0.7829
mistralai/Mistral-Small-24B-Instruct-2501,Precision,0.6736,0.3433,0.4633,0.3548,0.5943,0.5271
mistralai/Mistral-Small-24B-Instruct-2501,Recall,0.9583,0.7541,0.8367,0.6111,0.7875,0.9145
mistralai/Mistral-Small-24B-Instruct-2501,F1,0.7912,0.4718,0.5964,0.449,0.6774,0.6688
mistralai/Mistral-Small-24B-Instruct-2501,Accuracy,0.7571,0.7057,0.6829,0.7686,0.8286,0.6971
