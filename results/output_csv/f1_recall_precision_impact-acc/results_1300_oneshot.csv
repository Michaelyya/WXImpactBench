Model_Type,Metric,Infrastructural impact,Political impact,Financial impact,Ecological impact,Agricultural impact,Human health impact
gpt-4o,Precision,0.7162,0.5222,0.529,0.3871,0.6174,0.6645
gpt-4o,Recall,0.9464,0.7705,0.8367,0.6667,0.8875,0.8803
gpt-4o,F1,0.8154,0.6225,0.6482,0.4898,0.7282,0.7574
gpt-4o,Accuracy,0.7943,0.8371,0.7457,0.7857,0.8486,0.8114
gpt-4,Precision,0.6743,0.3333,0.4037,0.3472,0.5545,0.5497
gpt-4,Recall,0.875,0.7377,0.898,0.463,0.7625,0.8034
gpt-4,F1,0.7617,0.4592,0.557,0.3968,0.6421,0.6528
gpt-4,Accuracy,0.7371,0.6971,0.6,0.7829,0.8057,0.7143
mistralai/Mixtral-8x7B-Instruct-v0.1,Precision,0.7468,0.3333,0.4265,0.3077,0.4675,0.5902
mistralai/Mixtral-8x7B-Instruct-v0.1,Recall,0.7099,0.4068,0.617,0.3846,0.4737,0.6372
mistralai/Mixtral-8x7B-Instruct-v0.1,F1,0.7278,0.3664,0.5043,0.3419,0.4706,0.6128
mistralai/Mixtral-8x7B-Instruct-v0.1,Accuracy,0.7471,0.7559,0.6647,0.7735,0.7618,0.7324
gpt-3.5-turbo,Precision,0.7037,0.4138,0.3873,0.2909,0.5595,0.5854
gpt-3.5-turbo,Recall,0.9048,0.5902,0.6837,0.5926,0.5875,0.6154
gpt-3.5-turbo,F1,0.7917,0.4865,0.4945,0.3902,0.5732,0.6
gpt-3.5-turbo,Accuracy,0.7714,0.7829,0.6086,0.7143,0.8,0.7257
meta-llama/Llama-3.1-8B-Instruct,Precision,0.7529,0.3056,0.381,0.3,0.4545,0.5355
meta-llama/Llama-3.1-8B-Instruct,Recall,0.7798,0.7213,0.898,0.6667,0.75,0.7094
meta-llama/Llama-3.1-8B-Instruct,F1,0.7661,0.4293,0.535,0.4138,0.566,0.6103
meta-llama/Llama-3.1-8B-Instruct,Accuracy,0.7714,0.6657,0.5629,0.7086,0.7371,0.6971
Qwen/Qwen2.5-7B-Instruct,Precision,0.6404,0.4444,0.3706,0.2292,0.5588,0.4475
Qwen/Qwen2.5-7B-Instruct,Recall,0.869,0.1967,0.7449,0.8148,0.2375,0.6923
Qwen/Qwen2.5-7B-Instruct,F1,0.7374,0.2727,0.4949,0.3577,0.3333,0.5436
Qwen/Qwen2.5-7B-Instruct,Accuracy,0.7029,0.8171,0.5743,0.5486,0.7829,0.6114
mistralai/Mistral-7B-Instruct-v0.2,Precision,0.7278,0.3063,0.3152,0.2754,0.3351,0.5231
mistralai/Mistral-7B-Instruct-v0.2,Recall,0.7798,0.5574,0.8878,0.7037,0.8,0.5812
mistralai/Mistral-7B-Instruct-v0.2,F1,0.7529,0.3953,0.4652,0.3958,0.4723,0.5506
mistralai/Mistral-7B-Instruct-v0.2,Accuracy,0.7543,0.7029,0.4286,0.6686,0.5914,0.6829
deepseek-chat,Precision,0.7418,0.6458,0.584,0.3596,0.6477,0.6234
deepseek-chat,Recall,0.9405,0.5082,0.7449,0.5926,0.7125,0.8205
deepseek-chat,F1,0.8294,0.5688,0.6547,0.4476,0.6786,0.7085
deepseek-chat,Accuracy,0.8143,0.8657,0.78,0.7743,0.8457,0.7743
