Model_Type,Metric,Infrastructural impact,Political impact,Financial impact,Ecological impact,Agricultural impact,Human health impact
gpt-4,Precision,0.6569,0.3091,0.4069,0.3333,0.5327,0.526
gpt-4,Recall,0.8121,0.5667,0.8557,0.3148,0.7215,0.7043
gpt-4,F1,0.7263,0.4,0.5515,0.3238,0.6129,0.6022
gpt-4,Accuracy,0.7089,0.7061,0.611,0.7954,0.7925,0.6916
gpt-4o,Precision,0.7123,0.5493,0.531,0.407,0.6311,0.6643
gpt-4o,Recall,0.9455,0.65,0.7938,0.6481,0.8228,0.8087
gpt-4o,F1,0.8125,0.5954,0.6364,0.5,0.7143,0.7294
gpt-4o,Accuracy,0.7925,0.8473,0.7464,0.7983,0.8501,0.8012
mistralai/Mixtral-8x7B-Instruct-v0.1,Precision,0.6879,0.1667,0.3784,0.2286,0.4259,0.4842
mistralai/Mixtral-8x7B-Instruct-v0.1,Recall,0.6783,0.1,0.4719,0.3137,0.3239,0.4466
mistralai/Mixtral-8x7B-Instruct-v0.1,F1,0.6831,0.125,0.42,0.2645,0.368,0.4646
mistralai/Mixtral-8x7B-Instruct-v0.1,Accuracy,0.7059,0.7749,0.627,0.7138,0.7443,0.6581
gpt-3.5-turbo,Precision,0.6567,0.3258,0.3578,0.2651,0.5,0.5725
gpt-3.5-turbo,Recall,0.9273,0.4833,0.7526,0.8148,0.6709,0.6522
gpt-3.5-turbo,F1,0.7688,0.3893,0.485,0.4,0.573,0.6098
gpt-3.5-turbo,Accuracy,0.7349,0.7378,0.5533,0.6196,0.7723,0.7233
meta-llama/Llama-3.1-8B-Instruct,Precision,0.7419,0.2558,0.3641,0.3375,0.4579,0.5328
meta-llama/Llama-3.1-8B-Instruct,Recall,0.697,0.55,0.7732,0.5,0.6203,0.5652
meta-llama/Llama-3.1-8B-Instruct,F1,0.7188,0.3492,0.495,0.403,0.5269,0.5485
meta-llama/Llama-3.1-8B-Instruct,Accuracy,0.7406,0.6455,0.5591,0.7695,0.7464,0.6916
Qwen/Qwen2.5-7B-Instruct,Precision,0.6468,0.4828,0.3987,0.2549,0.6744,0.4203
Qwen/Qwen2.5-7B-Instruct,Recall,0.7879,0.2333,0.6289,0.7222,0.3671,0.5043
Qwen/Qwen2.5-7B-Instruct,F1,0.7104,0.3146,0.488,0.3768,0.4754,0.4585
Qwen/Qwen2.5-7B-Instruct,Accuracy,0.6945,0.8242,0.6311,0.6282,0.8156,0.6052
mistralai/Mistral-7B-Instruct-v0.2,Precision,0.7102,0.1867,0.3125,0.2556,0.3974,0.5586
mistralai/Mistral-7B-Instruct-v0.2,Recall,0.7576,0.2333,0.8247,0.4259,0.7848,0.5391
mistralai/Mistral-7B-Instruct-v0.2,F1,0.7331,0.2074,0.4533,0.3194,0.5277,0.5487
mistralai/Mistral-7B-Instruct-v0.2,Accuracy,0.737,0.6908,0.4422,0.7168,0.6792,0.7052
deepseek-chat,Precision,0.7366,0.6486,0.6095,0.3857,0.6364,0.6532
deepseek-chat,Recall,0.9152,0.4,0.6598,0.5,0.6203,0.7043
deepseek-chat,F1,0.8162,0.4948,0.6337,0.4355,0.6282,0.6778
deepseek-chat,Accuracy,0.804,0.8588,0.7867,0.7983,0.8329,0.7781
mistralai/Mistral-Small-24B-Instruct-2501,Precision,0.7039,0.4464,0.567,0.3333,0.55,0.5402
mistralai/Mistral-Small-24B-Instruct-2501,Recall,0.8841,0.4237,0.5729,0.3704,0.6962,0.8246
mistralai/Mistral-Small-24B-Instruct-2501,F1,0.7838,0.4348,0.5699,0.3509,0.6145,0.6528
mistralai/Mistral-Small-24B-Instruct-2501,Accuracy,0.7688,0.8121,0.7601,0.7861,0.8006,0.711
google/gemma-2-9b-it,Precision,0.6336,0.2609,0.3607,0.2378,0.4167,0.5163
google/gemma-2-9b-it,Recall,0.8963,0.4068,0.9167,0.6296,0.5696,0.8333
google/gemma-2-9b-it,F1,0.7424,0.3179,0.5176,0.3452,0.4813,0.6376
google/gemma-2-9b-it,Accuracy,0.7052,0.7023,0.526,0.6272,0.7197,0.6879
